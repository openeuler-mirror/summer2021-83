--- linux-4.4.283/kernel/sched/core.c	2021-09-03 15:43:08.000000000 +0800
+++ /usr/src/kernels/linux-4.4.283/kernel/sched/core.c	2021-09-27 07:24:12.771006984 +0800
@@ -75,6 +75,10 @@
 #include <linux/context_tracking.h>
 #include <linux/compiler.h>
 
+#include <linux/kernel.h>
+#include <linux/timekeeping.h>
+#include <uapi/linux/time.h>
+
 #include <asm/switch_to.h>
 #include <asm/tlb.h>
 #include <asm/irq_regs.h>
@@ -832,10 +836,14 @@ static void set_load_weight(struct task_
 
 static inline void enqueue_task(struct rq *rq, struct task_struct *p, int flags)
 {
+	struct timeval end_t;
 	update_rq_clock(rq);
 	if (!(flags & ENQUEUE_RESTORE))
 		sched_info_queued(rq, p);
 	p->sched_class->enqueue_task(rq, p, flags);
+	do_gettimeofday(&end_t);
+	p->runnable_s = end_t.tv_sec;
+	p->runnable_us = end_t.tv_usec;
 }
 
 static inline void dequeue_task(struct rq *rq, struct task_struct *p, int flags)
@@ -2693,6 +2701,8 @@ context_switch(struct rq *rq, struct tas
 	       struct task_struct *next)
 {
 	struct mm_struct *mm, *oldmm;
+	struct timeval start,end;
+	do_gettimeofday(&start);
 
 	prepare_task_switch(rq, prev, next);
 
@@ -2729,6 +2739,9 @@ context_switch(struct rq *rq, struct tas
 	switch_to(prev, next, prev);
 	barrier();
 
+	do_gettimeofday(&end);
+	next->context_switch_time = end.tv_usec - start.tv_usec;
+
 	return finish_task_switch(prev);
 }
 
@@ -3057,6 +3070,8 @@ pick_next_task(struct rq *rq, struct tas
 {
 	const struct sched_class *class = &fair_sched_class;
 	struct task_struct *p;
+	struct timeval start,end;
+	do_gettimeofday(&start);
 
 	/*
 	 * Optimization: we know that if all tasks are in
@@ -3071,7 +3086,8 @@ pick_next_task(struct rq *rq, struct tas
 		/* assumes fair_sched_class->next == idle_sched_class */
 		if (unlikely(!p))
 			p = idle_sched_class.pick_next_task(rq, prev);
-
+		do_gettimeofday(&end);
+		prev->pick_next_task_time = end.tv_usec - start.tv_usec;
 		return p;
 	}
 
@@ -3081,10 +3097,13 @@ again:
 		if (p) {
 			if (unlikely(p == RETRY_TASK))
 				goto again;
+			do_gettimeofday(&end);
+			prev->pick_next_task_time = end.tv_usec - start.tv_usec;
 			return p;
 		}
 	}
-
+	do_gettimeofday(&end);
+	prev->pick_next_task_time = end.tv_usec - start.tv_usec;
 	BUG(); /* the idle class will always have a runnable task */
 }
 
@@ -3201,11 +3220,15 @@ static void __sched notrace __schedule(b
 	if (likely(prev != next)) {
 		rq->nr_switches++;
 		rq->curr = next;
+		struct timeval r_time;
+		do_gettimeofday(&r_time);
+		next->runnable_time = r_time.tv_usec - next->runnable_us + (r_time.tv_sec - next->runnable_s) * 1000000;	
 		++*switch_count;
 
 		trace_sched_switch(preempt, prev, next);
 		rq = context_switch(rq, prev, next); /* unlocks the rq */
 		cpu = cpu_of(rq);
+		trace_sched_time(preempt, prev, next);
 	} else {
 		lockdep_unpin_lock(&rq->lock);
 		raw_spin_unlock_irq(&rq->lock);
